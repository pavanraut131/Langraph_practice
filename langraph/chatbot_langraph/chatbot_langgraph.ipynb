{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from  langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash', google_api_key = os.getenv('GEMINI_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AnyMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state:MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow =StateGraph(MessagesState)\n",
    "workflow.add_node('chatbot', call_model)\n",
    "workflow.add_edge(START, 'chatbot')\n",
    "workflow.add_edge('chatbot', END)\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagesState(TypedDict):\n",
    "    messages:Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query:str):\n",
    "    \"\"\"this is a custom tool \"\"\"\n",
    "    if 'sf' in query.lower() or \"san fransisco\" in query.lower():\n",
    "        return 'its 60 degress and foggy'\n",
    "    return 'its 90 degress and sunny '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state=MessagesState):\n",
    "    messages = state['messages']\n",
    "    resposne = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\":[resposne]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'search', 'arguments': '{\"query\": \"weather in San Francisco\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-1922a785-0b2a-4162-b90a-9d7d088d7ff9-0', tool_calls=[{'name': 'search', 'args': {'query': 'weather in San Francisco'}, 'id': '7572b7f7-261b-4bc2-a028-08d89a506eff', 'type': 'tool_call'}], usage_metadata={'input_tokens': 13, 'output_tokens': 6, 'total_tokens': 19, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposne = call_model({'messages':[\"how is weather in sf\"]})\n",
    "resposne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_function(state:MessagesState)->Literal[\"tools\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_messgaes = messages[-1]\n",
    "    if last_messgaes.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7d5e657c4eb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node('agent', call_model)\n",
    "workflow.add_node('tools', tool_node)\n",
    "workflow.add_edge(START,\"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", router_function, {\"tools\":\"tools\", END:END})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the weather in sf', additional_kwargs={}, response_metadata={}, id='6a29eed8-b859-4b62-8f60-f05b0020c511'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'search', 'arguments': '{\"query\": \"weather in sf\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-8437365a-03cc-4bfd-a783-d7d7cc20ff0b-0', tool_calls=[{'name': 'search', 'args': {'query': 'weather in sf'}, 'id': 'f6423d5f-ce35-4cd9-a09a-c982b0a68de6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 14, 'output_tokens': 5, 'total_tokens': 19, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='its 60 degress and foggy', name='search', id='6e8a4cec-c461-4760-9893-6c8c50a1d7cf', tool_call_id='f6423d5f-ce35-4cd9-a09a-c982b0a68de6')]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\":['What is the weather in sf']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7d5e657c4eb0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"tools\", 'agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7d5e657c4220>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\",call_model)\n",
    "workflow.add_node('tools', tool_node)\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges('agent', router_function, {\"tools\":\"tools\", END:END})\n",
    "workflow.add_edge(\"tools\", 'agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "app =  workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"thread_id\":\"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "events =app.stream({\"messages\":[\"hi there my name is pavan\"]}, config, stream_mode=\"values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi there my name is pavan\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Pavan, nice to meet you! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "for event in events:\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "events =app.stream({\"messages\":[\"hi what is my name\"]}, config, stream_mode=\"values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi what is my name\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Pavan.\n"
     ]
    }
   ],
   "source": [
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v': 3,\n",
       " 'ts': '2025-04-07T13:09:06.355609+00:00',\n",
       " 'id': '1f013b17-c458-68f4-8004-60ccb0ac276f',\n",
       " 'channel_versions': {'__start__': '00000000000000000000000000000005.0.7583310078978824',\n",
       "  'messages': '00000000000000000000000000000006.0.21738359510664818',\n",
       "  'branch:to:agent': '00000000000000000000000000000006.0.5194364469137897'},\n",
       " 'versions_seen': {'__input__': {},\n",
       "  '__start__': {'__start__': '00000000000000000000000000000004.0.3643336943363277'},\n",
       "  'agent': {'branch:to:agent': '00000000000000000000000000000005.0.6617083645779094'}},\n",
       " 'channel_values': {'messages': [HumanMessage(content='hi there my name is pavan', additional_kwargs={}, response_metadata={}, id='2eb98487-a192-4833-a3d9-1b5eb7f36f1d'),\n",
       "   AIMessage(content='Hello Pavan, nice to meet you! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-51fb29cb-707c-470f-9ca3-16b813baf07c-0', usage_metadata={'input_tokens': 15, 'output_tokens': 17, 'total_tokens': 32, 'input_token_details': {'cache_read': 0}}),\n",
       "   HumanMessage(content='hi what is my name', additional_kwargs={}, response_metadata={}, id='416d0399-a78b-447a-b0f9-47377928eec1'),\n",
       "   AIMessage(content='Your name is Pavan.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-5623378a-9376-4a7f-a0cb-82264bcdf451-0', usage_metadata={'input_tokens': 36, 'output_tokens': 7, 'total_tokens': 43, 'input_token_details': {'cache_read': 0}})]},\n",
       " 'pending_sends': []}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
